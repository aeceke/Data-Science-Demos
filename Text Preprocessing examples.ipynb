{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Special Character & Stopword Removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Removing Special Characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A RegEx, or Regular Expression, is a sequence of characters that forms a search pattern. RegEx can be used to check if a string contains the specified search pattern.\n",
    "\n",
    "Python has a built-in package called <code>re</code>, which can be used to work with Regular Expressions.\n",
    "\n",
    "More on regular expressions: https://www.w3schools.com/python/python_regex.asp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RegEx Example\n",
    "\n",
    "Search the string to see if it starts with \"The\" and ends with \"Spain\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YES! We have a match!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "txt = \"The rain in Spain\"\n",
    "x = re.search(\"^The.*Spain$\", txt)\n",
    "\n",
    "if x:\n",
    "  print(\"YES! We have a match!\")\n",
    "else:\n",
    "  print(\"No match\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Run the below code cell to create the <code>remove_special_characters</code> function. This function will allow you to remove special characters from a text string.\n",
    "\n",
    "A caret located in a bracket means ‘not.’ \n",
    "If remove_digits parameter is True, \"^a-zA-Z0-9\\s\" matches any characters other than \n",
    "alphabets ([a-zA-Z]) or digits ([0-9]), followed by a white space ([\\s]).\n",
    "If 'remove_digits' parameter is False, the the function will remove numbers as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T11:57:16.938919Z",
     "start_time": "2020-05-20T11:57:16.928944Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def remove_special_characters(text, remove_digits=False):\n",
    "    '''\n",
    "    A caret located in a bracket means ‘not.’ \n",
    "    If remove_digits parameter is True, \"^a-zA-Z0-9\\s\" matches any characters other than \n",
    "    alphabets ([a-zA-Z]) or digits ([0-9]), followed by a white space ([\\s]).\n",
    "    If 'remove_digits' parameter is False, the the function will remove numbers as well. \n",
    "    '''\n",
    "    pattern = r'[^a-zA-Z0-9\\s]' if not remove_digits else r'[^a-zA-z\\s]'\n",
    "    text = re.sub(pattern, '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Execute the function \"remove_special_characters\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The below example demonstrates two different executions of the <code>remove_special_characters</code> function for the following text.\n",
    "> \"Well this was fun! What do you think? 123#@\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T11:57:16.954874Z",
     "start_time": "2020-05-20T11:57:16.942907Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Well this was fun What do you think '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_special_characters(\"Well this was fun! What do you think? 123#@\", \n",
    "                          remove_digits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T11:57:16.967840Z",
     "start_time": "2020-05-20T11:57:16.956869Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Well this was fun What do you think 123'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_special_characters(\"Well this was fun! What do you think? 123#@\", \n",
    "                          remove_digits=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Removing Stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We will be importing the <code>nltk</code> package, which stands for Natural Language Toolkit. This is a suite of libraries and programs for symbolic and statistical natural language processing for English.\n",
    "\n",
    "<code>nltk</code> contains tools for pre-processing data, and we will be using these tools to remove stopwords, stem words, and lemmaztize words. \n",
    "\n",
    "More on <code>nltk</code> here: https://www.nltk.org/book/ch03.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T11:57:18.614945Z",
     "start_time": "2020-05-20T11:57:16.969835Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/andreaekey/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk # import nltk library\n",
    "\n",
    "from nltk.corpus import stopwords # stopwords tool\n",
    "from nltk.tokenize.toktok import ToktokTokenizer # word tokenization tool\n",
    "\n",
    "nltk.download('stopwords') # get the stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The code cell below will display a list of stopwords we will be removing from our text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T11:57:18.628905Z",
     "start_time": "2020-05-20T11:57:18.617934Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The below code cell will create the <code>remove_stopwords</code> function. This function will allow you to remove stopwords from a text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T11:57:18.647862Z",
     "start_time": "2020-05-20T11:57:18.630899Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tokenizer = ToktokTokenizer()\n",
    "stopword_list = nltk.corpus.stopwords.words('english')\n",
    "stopword_list.remove('no') # we will not remove 'no' from texts\n",
    "stopword_list.remove('not') # we will not remove 'not' from texts\n",
    "\n",
    "def remove_stopwords(text, is_lower_case=False):\n",
    "    # First, tokenize the text\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    # remove whitespaces in each token\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    # if \"is_lower_case\" parameter is True, \n",
    "    # we will not remove stopwords that have any upper case letter\n",
    "    if is_lower_case: \n",
    "        filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "    # If \"is_lower_case\" parameter is False, \n",
    "    # we will remove any stopwords no matter whether they are in uppercase or not\n",
    "    else:\n",
    "        filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
    "    filtered_text = ' '.join(filtered_tokens)    \n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Execute the function \"remove_stopwords\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The below example demonstrates two different executions of the <code>remove_stopwords</code> function for the following text.\n",
    "> \"The, and, if are StopWords, computer is not\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T11:57:18.661826Z",
     "start_time": "2020-05-20T11:57:18.650845Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "', , StopWords , computer not'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stopwords(\"The, and, if are StopWords, computer is not\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T11:57:18.678772Z",
     "start_time": "2020-05-20T11:57:18.665807Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The , , StopWords , computer not'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stopwords(\"The, and, if are StopWords, computer is not\", is_lower_case=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Exercise (Stopword Removal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Consider the below product reviews:  \n",
    "  \n",
    "1. The product is really very good. – POSITIVE  \n",
    "2. The product seems to be good. – POSITIVE  \n",
    "3. Good product. I really liked it. – POSITIVE  \n",
    "4. The product is not good. – NEGATIVE  \n",
    "5. I didn’t like the product. – NEGATIVE  \n",
    "\n",
    "Each numbered review has the review text on the left and the label on the right. A product review will be labeled either 'POSITIVE' or 'NEGATIVE'.\n",
    "\n",
    "Remove stopwords in each review using the code provided earlier in the module. Observe what happens to the review comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T11:57:18.701709Z",
     "start_time": "2020-05-20T11:57:18.681763Z"
    },
    "hidden": true,
    "slideshow": {
     "slide_type": "-"
    },
    "solution2": "hidden"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product really good .\n",
      "product seems good .\n",
      "Good product. really liked .\n",
      "product not good .\n",
      "’ like product .\n"
     ]
    }
   ],
   "source": [
    "# remove stopwords from review text\n",
    "rm1 = remove_stopwords (\"The product is really very good.\")\n",
    "rm2 = remove_stopwords (\"The product seems to be good.\")\n",
    "rm3 = remove_stopwords (\"Good product. I really liked it.\")\n",
    "rm4 = remove_stopwords (\"The product is not good.\")\n",
    "rm5 = remove_stopwords (\"I didn’t like the product.\")\n",
    "\n",
    "print(rm1)\n",
    "print(rm2)\n",
    "print(rm3)\n",
    "print(rm4)\n",
    "print(rm5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The meaning of Review 5 is changed after removing stop words. This is because the\n",
    "NLTK's stopword list contains contractions of negative expressions like 'didn't,\" \n",
    "\"doesn't,\" \"hadn't,\" etc.\n",
    "Removing stop words, especially when it comes to negative contractions like 'didn't,' \n",
    "can change the meaning of an original text. We should remove stop words with care."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Stemming & Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Run the below code cell to create the <code>simple_stemmer</code> function. This function will allow you to stem words in a text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T11:57:18.730635Z",
     "start_time": "2020-05-20T11:57:18.719662Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def simple_stemmer(text):\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    # split the text into individual word and return a list of words\n",
    "    # the 'ps' function stems each word, and .join() function joins the stemmed words with whitespace.\n",
    "    text = ' '.join([ps.stem(word) for word in text.split()]) \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Execute the function \"simple_stemmer\"**\n",
    "\n",
    "The below example demonstrates a sample execution of the function <code>simple_stemmer</code> function for the following text.\n",
    "> \"My system keeps crashing his crashed yesterday, ours crashes daily\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T11:57:18.752573Z",
     "start_time": "2020-05-20T11:57:18.735619Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My system keep crash hi crash yesterday, our crash daili'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_stemmer(\"My system keeps crashing his crashed yesterday, ours crashes daily\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Run the below code cell to create the <code>lemmatize_text</code> function. This function will allow you to lemmatize words in a text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T11:57:18.896189Z",
     "start_time": "2020-05-20T11:57:18.757560Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/andreaekey/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/andreaekey/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer # word lemmatization tool\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    s = \" \" # create an empty string that later will contain lemmatized words,\n",
    "    t_l = [] # create an empty list\n",
    "    t_w = nltk.word_tokenize(text) # tokenize the text\n",
    "    # assign the list of tokenized words into t_w.\n",
    "    for w in t_w:\n",
    "        # “pos” is a part of speech parameter and “v” means verbs. \n",
    "        # We will lemmatize verbs only. \n",
    "        l_w = wordnet_lemmatizer.lemmatize(w, pos=\"v\")\n",
    "        # append l_w into the list t_l\n",
    "        t_l.append(l_w)\n",
    "    # joint the tokens to make a complete sentence\n",
    "    text = s.join(t_l)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Sample execution of the function \"lemmatize_text\"\n",
    "\n",
    "The below example demonstrates a sample execution of the function <code>lemmatize_text</code> function for the following text.\n",
    "> \"My system keeps crashing! his was crashed yesterday, ours crashes daily\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T11:57:21.706826Z",
     "start_time": "2020-05-20T11:57:18.900183Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My system keep crash ! his be crash yesterday , ours crash daily'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatize_text(\"My system keeps crashing! his was crashed yesterday, ours crashes daily\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Exercise  (Text Preprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "1) Remove special characters (including numbers) and stopwords.\n",
    "\n",
    "2) Lemmatize the following paragraph. \n",
    "\n",
    "  \n",
    "> “We measured the serum lipid profile, together with plasma fibrinogen and serum lipoprotein(a) (Lp[a]), glucose, bilirubin, and albumin levels in 491 patients (310 men) who were referred for the management of primary dyslipidemia. All these variables have been shown to predict vascular events. The patients were not taking lipid-lowering drugs; hypertension was present in 156 (31.7%) of them. Of the hypertensive patients, 52 (33%) were not receiving any treatment to control their blood pressure. Lipid-hostile antihypertensive drugs were associated with a significantly higher fibrinogen concentration when compared with untreated hypertensives or those taking lipid-neutral/lipid-friendly drugs (median values: 383, 353, and 336 mg/dL, respectively; P < .01). Lipid-neutral/lipid-friendly antihypertensive drugs were associated with lower Lp(a) levels when compared with untreated hypertensives (median values: 22 and 45 mg/dL, respectively; P < .05). The serum bilirubin level was significantly lower in the untreated hypertensives when compared with normotensives or the treated hypertensives. There were no significant differences in lipids, glucose, or albumin among the groups of hypertensives or normotensives. The influence of antihypertensive drugs on additional cardiovascular risk factors should be considered when selecting medication to reduce blood pressure.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T11:57:21.719783Z",
     "start_time": "2020-05-20T11:57:21.709811Z"
    },
    "hidden": true,
    "solution2": "hidden"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "measure serum lipid profile together plasma fibrinogen serum lipoproteina Lpa glucose bilirubin albumin level 491 patients 310 men refer management primary dyslipidemia variables show predict vascular events patients not take lipidlowering drug hypertension present 156 317 hypertensive patients 52 33 not receive treatment control blood pressure Lipidhostile antihypertensive drug associate significantly higher fibrinogen concentration compare untreated hypertensives take lipidneutrallipidfriendly drug median value 383 353 336 mgdL respectively P 01 Lipidneutrallipidfriendly antihypertensive drug associate lower Lpa level compare untreated hypertensives median value 22 45 mgdL respectively P 05 serum bilirubin level significantly lower untreated hypertensives compare normotensives treat hypertensives no significant differences lipids glucose albumin among group hypertensives normotensives influence antihypertensive drug additional cardiovascular risk factor consider select medication reduce blood pressure\n"
     ]
    }
   ],
   "source": [
    "text = \"We measured the serum lipid profile, together with plasma fibrinogen and serum lipoprotein(a) (Lp[a]), glucose, bilirubin, and albumin levels in 491 patients (310 men) who were referred for the management of primary dyslipidemia. All these variables have been shown to predict vascular events. The patients were not taking lipid-lowering drugs; hypertension was present in 156 (31.7%) of them. Of the hypertensive patients, 52 (33%) were not receiving any treatment to control their blood pressure. Lipid-hostile antihypertensive drugs were associated with a significantly higher fibrinogen concentration when compared with untreated hypertensives or those taking lipid-neutral/lipid-friendly drugs (median values: 383, 353, and 336 mg/dL, respectively; P < .01). Lipid-neutral/lipid-friendly antihypertensive drugs were associated with lower Lp(a) levels when compared with untreated hypertensives (median values: 22 and 45 mg/dL, respectively; P < .05). The serum bilirubin level was significantly lower in the untreated hypertensives when compared with normotensives or the treated hypertensives. There were no significant differences in lipids, glucose, or albumin among the groups of hypertensives or normotensives. The influence of antihypertensive drugs on additional cardiovascular risk factors should be considered when selecting medication to reduce blood pressure.\"\n",
    "# remove special characters\n",
    "rm_sc = remove_special_characters(text)\n",
    "# remove stopwords\n",
    "rm_sw = remove_stopwords(rm_sc)\n",
    "# lemmatize words\n",
    "final_text = lemmatize_text(rm_sw)\n",
    "\n",
    "print(final_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
